{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1d2a4c2",
   "metadata": {},
   "source": [
    "# Q4 Transfer Learning with Pre-trained CNN \n",
    "Use a pre-trained convolutional neural network (CNN) as a feature extractor and fine-\n",
    "tune a classifier on a subset of the CIFAR-10 dataset. Set random seeds to 42. Follow\n",
    "the configuration below:\n",
    "- Load CIFAR-10 and normalize pixel values to [0,1]\n",
    "- Use only the first 2000 training samples and first 500 test samples\n",
    "- Load MobileNetV2 from tensorflow.keras.applications, with include top=False and weights=’imagenet’\n",
    "- Freeze all layers of the pre-trained base\n",
    "- Add a classifier on top:\n",
    "- GlobalAveragePooling2D\n",
    "- Dense layer with 128 neurons, ReLU activation\n",
    "- Dropout: 0.2\n",
    "- Output layer: 10 neurons with softmax\n",
    "- Optimizer: Adam, learning rate = 0.001\n",
    "- Loss: sparse categorical crossentropy\n",
    "- epochs = 5, batch size = 32\n",
    "\n",
    "Q4.1 Report the test accuracy of the model.\n",
    "\n",
    "### Imports and seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6a8abc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbcae7b",
   "metadata": {},
   "source": [
    "## Loading CIFAR-10 with subsets and adjusting for MobileNet\n",
    "\n",
    "Why adjust and what is MobileNet?? From [GeeksForGeeks](https://www.geeksforgeeks.org/computer-vision/what-is-mobilenet-v2/)\n",
    "\n",
    "MobileNet V2 is a powerful and efficient convolutional neural network architecture designed for mobile and embedded vision applications. Developed by Google, MobileNet V2 builds upon the success of its predecessor, MobileNet V1, by introducing several innovative improvements that enhance its performance and efficiency. \n",
    "But more importantly for us: MobileNetV2 has an input layer of 224x224 pixels as input, so the model is trained to recognize 224x224 images, that’s the size it was trained on when it learned to recognize features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "765b267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Adjusting image size for MobileNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Standard normalization for 3 channels\n",
    "])\n",
    "\n",
    "train_full = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "test_full = datasets.CIFAR10('./data', train=False, download=True, transform=transform) \n",
    "\n",
    "train_subset = Subset(train_full, range(2000))\n",
    "test_subset = Subset(test_full, range(500)) \n",
    "\n",
    "# split into train and validation sets\n",
    "train_size = int(0.8 * len(train_subset))\n",
    "val_size = len(train_subset) - train_size\n",
    "train_subset, val_subset = torch.utils.data.random_split(train_subset, [train_size, val_size], \n",
    "                                                         generator=torch.Generator().manual_seed(seed))\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addec077",
   "metadata": {},
   "source": [
    "### Load MobileNetV2 base\n",
    "In the task it specifies using MobileNetV2 from tensorflow.keras.applications. But since i use PyTorch, the pre-trained model is loaded from torchvision.models instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6d026b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: Train Acc: 0.3581, Val Acc: 0.5175\n",
      "Epoch 2/5: Train Acc: 0.5950, Val Acc: 0.6425\n",
      "Epoch 3/5: Train Acc: 0.6694, Val Acc: 0.6800\n",
      "Epoch 4/5: Train Acc: 0.7200, Val Acc: 0.6900\n",
      "Epoch 5/5: Train Acc: 0.7344, Val Acc: 0.7025\n",
      "Test Accuracy: 0.6620\n"
     ]
    }
   ],
   "source": [
    "# Freeze all convolutional layers\n",
    "for param in mobilenet.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace classifier\n",
    "num_features = mobilenet.last_channel  # 1280\n",
    "mobilenet.classifier = nn.Sequential(\n",
    "    nn.Linear(num_features, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(128, 10)\n",
    ")\n",
    "\n",
    "mobilenet = mobilenet.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(mobilenet.parameters(), lr=0.001)\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # Training\n",
    "    mobilenet.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mobilenet(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Validation\n",
    "    mobilenet.eval()\n",
    "    val_loss = 0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in val_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = mobilenet(X)\n",
    "            loss = criterion(outputs, y)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_val += (preds == y).sum().item()\n",
    "            total_val += y.size(0)\n",
    "    val_acc = correct_val / total_val\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}: Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "# Test evaluation\n",
    "mobilenet.eval()\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "with torch.no_grad():\n",
    "    for X, y in test_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        outputs = mobilenet(X)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_test += (preds == y).sum().item()\n",
    "        total_test += y.size(0)\n",
    "\n",
    "test_acc = correct_test / total_test\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec513e4",
   "metadata": {},
   "source": [
    "MobileNetV2 already knows how to detect general image features like edges, colors, and textures from ImageNet. By freezing these layers and only training the new classifier, the model reuses this knowledge to recognize images from CIFAR. With a relatively small dataset of 2,000 samples, the train and validation accuracy doe simprove, reaching around 73% train and 70% validation accuracy. The test accuracy is 66%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
